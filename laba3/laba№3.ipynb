{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting BeautifulSoup\n",
      "  Using cached BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"d:\\Р’РЈР—\\РёРЅР¶РµРЅРёСЂРµРЅРі РґР°РЅРЅС‹С…\\github\\DataEngineeringHomework\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"d:\\Р’РЈР—\\РёРЅР¶РµРЅРёСЂРµРЅРі РґР°РЅРЅС‹С…\\github\\DataEngineeringHomework\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"d:\\Р’РЈР—\\РёРЅР¶РµРЅРёСЂРµРЅРі РґР°РЅРЅС‹С…\\github\\DataEngineeringHomework\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-1r2ithwr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-1r2ithwr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-1r2ithwr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 522, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-1r2ithwr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 3\n",
      "          \"You're trying to run a very old release of Beautiful Soup under Python 3. This will not work.\"<>\"Please use Beautiful Soup 4, available through the pip package 'beautifulsoup4'.\"\n",
      "                                                                                                         ^^\n",
      "      SyntaxError: invalid syntax\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\вуз\\инжениренг данных\\github\\dataengineeringhomework\\.venv\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install BeautifulSoup\n",
    "!pip install requests\n",
    "\n",
    "folder_result = './result'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Вариант №36***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def parse_html_to_json(folder, folder_result, fileName):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".html\"):\n",
    "            with open(os.path.join(folder, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                soup = BeautifulSoup(file, \"html.parser\")\n",
    "                [address, index] = (\n",
    "                    soup.find(\"p\", class_=\"address-p\")\n",
    "                    .text.split(\"Улица:\")[1]\n",
    "                    .split(\"Индекс:\")\n",
    "                )\n",
    "                item = {\n",
    "                    \"fileName\": filename,\n",
    "                    \"building\": soup.find(\"h1\", class_=\"title\")\n",
    "                    .text.split(\"Строение:\")[1]\n",
    "                    .strip(),\n",
    "                    \"address\": address.strip(),\n",
    "                    \"index\": int(index.strip()),\n",
    "                    \"floors\": int(\n",
    "                        soup.find(\"span\", class_=\"floors\")\n",
    "                        .text.split(\"Этажи:\")[1]\n",
    "                        .strip()\n",
    "                    ),\n",
    "                    \"year\": int(\n",
    "                        soup.find(\"span\", class_=\"year\")\n",
    "                        .text.split(\"Построено в\")[1]\n",
    "                        .strip()\n",
    "                    ),\n",
    "                    \"rating\": float(\n",
    "                        soup.find(\"div\", class_=\"build-wrapper\")\n",
    "                        .find_all(\"div\")[-1]\n",
    "                        .find_all(\"span\")[0]\n",
    "                        .text.split(\"Рейтинг:\")[1]\n",
    "                        .strip()\n",
    "                    ),\n",
    "                    \"views\": int(\n",
    "                        soup.find(\"div\", class_=\"build-wrapper\")\n",
    "                        .find_all(\"div\")[-1]\n",
    "                        .find_all(\"span\")[-1]\n",
    "                        .text.split(\"Просмотры:\")[1]\n",
    "                        .strip()\n",
    "                    ),\n",
    "                    \"isParking\": (\n",
    "                        True\n",
    "                        if soup.find(\"div\", class_=\"build-wrapper\")\n",
    "                        .find_all(\"div\")[2]\n",
    "                        .find_all(\"span\")[-1]\n",
    "                        .text.split(\"Парковка:\")[1]\n",
    "                        .strip()\n",
    "                        == \"есть\"\n",
    "                        else False\n",
    "                    ),\n",
    "                }\n",
    "                data.append(item)\n",
    "\n",
    "    # Сортировка по ключу \"year\"\n",
    "    data = sorted(data, reverse=True, key=lambda x: x[\"year\"])\n",
    "\n",
    "    columnViews = \"views\"\n",
    "    columnIsParking = \"isParking\"\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Статистические характеристики по колонке \"views\"\n",
    "    views_sum = df[columnViews].sum()\n",
    "    views_min = df[columnViews].min()\n",
    "    views_max = df[columnViews].max()\n",
    "    views_mean = df[columnViews].mean()\n",
    "    views_median = df[columnViews].median()\n",
    "\n",
    "    # Частота меток по колонке \"isParking\"\n",
    "    is_parking_counts = df[columnIsParking].value_counts().to_dict()\n",
    "\n",
    "    statistical_characteristics_views = {\n",
    "        \"views_sum\": views_sum,\n",
    "        \"views_min\": views_min,\n",
    "        \"views_max\": views_max,\n",
    "        \"views_mean\": views_mean,\n",
    "        \"views_median\": views_median,\n",
    "    }\n",
    "\n",
    "    with open(\n",
    "        os.path.join(folder_result, fileName), \"w\", encoding=\"utf-8\"\n",
    "    ) as json_file:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"is_parking_counts\": is_parking_counts,\n",
    "                \"statistical_characteristics_views\": statistical_characteristics_views,\n",
    "                \"dataset\": data,\n",
    "            },\n",
    "            json_file,\n",
    "            cls=NpEncoder,\n",
    "            ensure_ascii=False,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "\n",
    "folder = \"./data/1\"\n",
    "fileName = \"data_result№1.json\"\n",
    "parse_html_to_json(folder, folder_result, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def parse_html_to_json(folder, folder_result, fileName):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".html\"):\n",
    "            with open(os.path.join(folder, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                soup = BeautifulSoup(file, \"html.parser\")\n",
    "                allHTMLItems = soup.findAll(\"div\", class_=\"pad\")\n",
    "                for HTMLItem in allHTMLItems:\n",
    "                    item = {\n",
    "                        \"filename\": filename,\n",
    "                        \"title\": HTMLItem.find(\"span\").text.strip(),\n",
    "                        \"coins_card\": int(\n",
    "                            HTMLItem.find(\"strong\").text.strip().split(\" \")[2]\n",
    "                        ),\n",
    "                        \"price\": int(\n",
    "                            HTMLItem.find(\"price\").text.split(\"₽\")[0].replace(\" \", \"\")\n",
    "                        ),\n",
    "                        \"matrix\": (\n",
    "                            HTMLItem.find(\"li\", attrs={\"type\": \"matrix\"}).text.strip()\n",
    "                            if HTMLItem.find(\"li\", attrs={\"type\": \"matrix\"}) != None\n",
    "                            else None\n",
    "                        ),\n",
    "                    }\n",
    "                    data.append(item)\n",
    "\n",
    "    # Сортировка по ключу \"price\"\n",
    "    data = sorted(data, key=lambda x: x[\"price\"])\n",
    "\n",
    "    column_coins_card = \"coins_card\"\n",
    "    columnIsParking = \"matrix\"\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Статистические характеристики по колонке \"coins_card\"\n",
    "    coins_card_sum = df[column_coins_card].sum()\n",
    "    coins_card_min = df[column_coins_card].min()\n",
    "    coins_card_max = df[column_coins_card].max()\n",
    "    coins_card_mean = df[column_coins_card].mean()\n",
    "    coins_card_median = df[column_coins_card].median()\n",
    "\n",
    "    # Частота меток по колонке \"isParking\"\n",
    "    matrix_types = df[columnIsParking].value_counts().to_dict()\n",
    "\n",
    "    statistical_characteristics_coins_card = {\n",
    "        \"coins_card_sum\": coins_card_sum,\n",
    "        \"coins_card_min\": coins_card_min,\n",
    "        \"coins_card_max\": coins_card_max,\n",
    "        \"coins_card_mean\": coins_card_mean,\n",
    "        \"coins_card_median\": coins_card_median,\n",
    "    }\n",
    "\n",
    "    with open(\n",
    "        os.path.join(folder_result, fileName), \"w\", encoding=\"utf-8\"\n",
    "    ) as json_file:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"matrix_types\": matrix_types,\n",
    "                \"statistical_characteristics_coins_card\": statistical_characteristics_coins_card,\n",
    "                \"dataset\": data,\n",
    "            },\n",
    "            json_file,\n",
    "            cls=NpEncoder,\n",
    "            ensure_ascii=False,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "\n",
    "folder = \"./data/2\"\n",
    "fileName = \"data_result№2.json\"\n",
    "parse_html_to_json(folder, folder_result, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def parse_xml_to_json(folder, folder_result, fileName):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(folder, filename))\n",
    "            root = tree.getroot()\n",
    "            item = {\n",
    "                \"filename\": filename,\n",
    "                \"name\": root.find(\"name\").text.strip(),\n",
    "                \"constellation\": root.find(\"constellation\").text.strip(),\n",
    "                \"spectral_class\": root.find(\"spectral-class\").text.strip(),\n",
    "                \"radius\": int(root.find(\"radius\").text.strip()),\n",
    "                \"rotation\": float(root.find(\"rotation\").text.split()[0]),\n",
    "                \"age\": float(root.find(\"age\").text.split()[0]),\n",
    "                \"distance\": float(root.find(\"distance\").text.split()[0]),\n",
    "                \"absolute_magnitude\": float(root.find(\"absolute-magnitude\").text.split()[0]),\n",
    "            }\n",
    "            data.append(item)\n",
    "\n",
    "    # Сортировка по ключу \"age\"\n",
    "    data = sorted(data, key=lambda x: x[\"age\"])\n",
    "\n",
    "    column_radius = \"radius\"\n",
    "    column_constellation = \"constellation\"\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Статистические характеристики по колонке \"radius\"\n",
    "    radius_sum = df[column_radius].sum()\n",
    "    radius_min = df[column_radius].min()\n",
    "    radius_max = df[column_radius].max()\n",
    "    radius_mean = df[column_radius].mean()\n",
    "    radius_median = df[column_radius].median()\n",
    "\n",
    "    # Частота меток по колонке \"constellation\"\n",
    "    constellation_counts = df[column_constellation].value_counts().to_dict()\n",
    "\n",
    "    statistical_characteristics_radius = {\n",
    "        \"radius_sum\": radius_sum,\n",
    "        \"radius_min\": radius_min,\n",
    "        \"radius_max\": radius_max,\n",
    "        \"radius_mean\": radius_mean,\n",
    "        \"radius_median\": radius_median,\n",
    "    }\n",
    "\n",
    "    with open(\n",
    "        os.path.join(folder_result, fileName), \"w\", encoding=\"utf-8\"\n",
    "    ) as json_file:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"constellation_counts\": constellation_counts,\n",
    "                \"statistical_characteristics_radius\": statistical_characteristics_radius,\n",
    "                \"dataset\": data,\n",
    "            },\n",
    "            json_file,\n",
    "            cls=NpEncoder,\n",
    "            ensure_ascii=False,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "\n",
    "folder = \"./data/3\"\n",
    "fileName = \"data_result№3.json\"\n",
    "parse_xml_to_json(folder, folder_result, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def parse_xml_to_json(folder, folder_result, fileName):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(folder, filename))\n",
    "            root = tree.getroot()\n",
    "            for clothing in root.findall(\"clothing\"):\n",
    "                item = {}\n",
    "                for child in clothing:\n",
    "                    item[child.tag] = child.text.strip() if child.text else None\n",
    "                data.append(item)\n",
    "\n",
    "    # Сортировка по ключу \"price\"\n",
    "    data = sorted(data, key=lambda x: int(x[\"price\"]) if x[\"price\"] else 0)\n",
    "\n",
    "    column_price = \"price\"\n",
    "    column_color = \"color\"\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Статистические характеристики по колонке \"price\"\n",
    "    df[column_price] = pd.to_numeric(df[column_price], errors='coerce')\n",
    "    price_sum = df[column_price].sum()\n",
    "    price_min = df[column_price].min()\n",
    "    price_max = df[column_price].max()\n",
    "    price_mean = df[column_price].mean()\n",
    "    price_median = df[column_price].median()\n",
    "\n",
    "    # Частота меток по колонке \"color\"\n",
    "    color_counts = df[column_color].value_counts().to_dict()\n",
    "\n",
    "    statistical_characteristics_price = {\n",
    "        \"price_sum\": price_sum,\n",
    "        \"price_min\": price_min,\n",
    "        \"price_max\": price_max,\n",
    "        \"price_mean\": price_mean,\n",
    "        \"price_median\": price_median,\n",
    "    }\n",
    "\n",
    "    with open(\n",
    "        os.path.join(folder_result, fileName), \"w\", encoding=\"utf-8\"\n",
    "    ) as json_file:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"color_counts\": color_counts,\n",
    "                \"statistical_characteristics_price\": statistical_characteristics_price,\n",
    "                \"dataset\": data,\n",
    "            },\n",
    "            json_file,\n",
    "            cls=NpEncoder,\n",
    "            ensure_ascii=False,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "\n",
    "folder = \"./data/4\"\n",
    "fileName = \"data_result№4.json\"\n",
    "parse_xml_to_json(folder, folder_result, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def parse_html_to_json(folder, folder_result, fileName):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".html\"):\n",
    "            with open(os.path.join(folder, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                soup = BeautifulSoup(file, \"html.parser\")\n",
    "                cars = soup.find_all(\"div\", class_=\"ListingItem\")\n",
    "                for car in cars:\n",
    "                    price = (\n",
    "                        int(\n",
    "                            car.find(\"div\", class_=\"ListingItemPrice__content\")\n",
    "                            .text.strip()\n",
    "                            .replace(\"\\xa0\", \"\")\n",
    "                            .replace(\"от\", \"\")\n",
    "                            .replace(\"₽\", \"\")\n",
    "                        )\n",
    "                        if car.find(\"div\", class_=\"ListingItemPrice__content\") != None\n",
    "                        else 0\n",
    "                    )\n",
    "                    mileage = (\n",
    "                        int(\n",
    "                            car.find(\"div\", class_=\"ListingItem__kmAge\")\n",
    "                            .text.strip()\n",
    "                            .replace(\"\\xa0\", \"\")\n",
    "                            .replace(\"км\", \"\")\n",
    "                            .replace(\"Новый\", \"0\")\n",
    "                        )\n",
    "                        if car.find(\"div\", class_=\"ListingItem__kmAge\") != None\n",
    "                        else None\n",
    "                    )\n",
    "                    item = {\n",
    "                        \"title\": car.find(\n",
    "                            \"a\", class_=\"ListingItemTitle__link\"\n",
    "                        ).text.strip(),\n",
    "                        \"price\": price,\n",
    "                        \"year\": int(\n",
    "                            car.find(\"div\", class_=\"ListingItem__year\").text.strip()\n",
    "                        ),\n",
    "                        \"mileage\": mileage,\n",
    "                        \"type\": car.findAll(\n",
    "                            \"div\", class_=\"ListingItemTechSummaryDesktop__cell\"\n",
    "                        )[1].text.strip(),\n",
    "                    }\n",
    "                    data.append(item)\n",
    "\n",
    "    # Сортировка по ключу \"price\"\n",
    "    data = sorted(data, key=lambda x: x[\"price\"])\n",
    "\n",
    "    column_mileage = \"mileage\"\n",
    "    column_location = \"type\"\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Статистические характеристики по колонке \"price\"\n",
    "    mileage_sum = df[column_mileage].sum()\n",
    "    mileage_min = df[column_mileage].min()\n",
    "    mileage_max = df[column_mileage].max()\n",
    "    mileage_mean = df[column_mileage].mean()\n",
    "    mileage_median = df[column_mileage].median()\n",
    "\n",
    "    statistical_characteristics_mileage = {\n",
    "        \"mileage_sum\": mileage_sum,\n",
    "        \"mileage_min\": mileage_min,\n",
    "        \"mileage_max\": mileage_max,\n",
    "        \"mileage_mean\": mileage_mean,\n",
    "        \"mileage_median\": mileage_median,\n",
    "    }\n",
    "\n",
    "    # Частота меток по колонке \"type\"\n",
    "    type_counts = df[column_location].value_counts().to_dict()\n",
    "\n",
    "    with open(\n",
    "        os.path.join(folder_result, fileName), \"w\", encoding=\"utf-8\"\n",
    "    ) as json_file:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"type_counts\": type_counts,\n",
    "                \"statistical_characteristics_mileage\": statistical_characteristics_mileage,\n",
    "                \"dataset\": data,\n",
    "            },\n",
    "            json_file,\n",
    "            cls=NpEncoder,\n",
    "            ensure_ascii=False,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "\n",
    "folder = \"./data/5\"\n",
    "fileName = \"data_result№5.json\"\n",
    "parse_html_to_json(folder, folder_result, fileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
